# -*- coding: utf-8 -*-
"""Predictive analitics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BkxTZ_DyNv9_gscmlxYm73nUKtoVvMzs

#Predictive Analytics - Crop Recommendation

Nama: Atika Oktavianti

Username: atika_oktavianti_0gNF

Domain yang saya pilih untuk proyek machine learning ini adalah Pertanian, dengan judul Rekomendasi jenis tanaman berdasarkan kondisi lingkungan.

**Mengunduh dataset dari kaggle**
"""

# Memasang Kaggle API
!pip install -q kaggle

# Upload file kaggle.json
from google.colab import files
files.upload()

# Mengunduh dataset dari Kaggle
!kaggle datasets download -d atharvaingle/crop-recommendation-dataset

# Mengekstrak file zip
!unzip -q crop-recommendation-dataset.zip

"""#Import Library

Mengimport library yang dibutuhkan
"""

# Import library dasar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Untuk modelling dan evaluasi
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

"""#Load Dataset

Memuat dataset yang sudah diunduh dari kaggle
"""

# Menampilkan semua kolom
pd.set_option('display.max_columns', None)
# Load dataset
df = pd.read_csv('Crop_recommendation.csv')

# Tampilkan 5 baris pertama
df.head()

"""Output tersebut merupakan cuplikan awal dari dataset rekomendasi tanaman (Crop Recommendation Dataset). Dataset ini berisi informasi tentang kondisi lingkungan dan unsur hara tanah yang digunakan untuk memprediksi jenis tanaman (label) yang cocok ditanam.

#Eksplorasi Data Awal (EDA) dan Visualisasi Data

Melihat jumlah baris dan kolom pada dataset
"""

# Ukuran dataset
print(f"Jumlah baris dan kolom: {df.shape}")

"""pada output tersebut terdapat 2200 baris dan 8 kolom"""

# Informasi tipe data
df.info()

# Statistik deskriptif
df.describe()

"""Output tersebut menunjukkan ringkasan statistik dari fitur numerik dalam dataset. Rata-rata suhu adalah 25.62Â°C, kelembaban 71.48%, pH tanah 6.47, dan curah hujan 103.46 mm. Kandungan unsur hara N, P, dan K masing-masing rata-rata 50.55, 53.36, dan 48.15. Nilai minimum dan maksimum tiap fitur menunjukkan variasi data yang cukup besar, yang penting untuk mendukung model klasifikasi tanaman.

**Mengecek missing value**

Pengecekan missing value penting dilakukan untuk memastikan kualitas data sebelum analisis atau pelatihan model, karena data yang hilang dapat menyebabkan bias atau error.
"""

#Cek missing values
print("Jumlah missing value di setiap kolom:")
print(df.isnull().sum())

"""Output di atas menunjukkan bahwa tidak ada missing value di semua kolom (jumlahnya 0), sehingga dataset ini sudah bersih dan siap digunakan untuk proses selanjutnya tanpa perlu penanganan khusus terhadap data yang hilang.

**Mengecek Jumlah Target (jenis tanaman)**

Pengecekan jumlah target tanaman penting untuk memahami cakupan klasifikasi yang akan dilakukan.
"""

# Jumlah kelas target
print("Jumlah kelas tanaman unik:", df['label'].nunique())
print("\nDaftar jenis tanaman:")
print(df['label'].unique())

"""Output menunjukkan bahwa terdapat 22 kelas tanaman unik dalam dataset. Informasi ini membantu memastikan bahwa model akan belajar membedakan berbagai jenis tanaman berdasarkan kondisi lingkungan yang beragam.

**Visualisasi distribusi label tanaman**

Visualisasi ini agar dapat menunjukkan distribusi jumlah data untuk setiap jenis tanaman dalam dataset.
"""

plt.figure(figsize=(12, 6))
sns.countplot(data=df, x='label', order=df['label'].value_counts().index)
plt.xticks(rotation=90)
plt.title('Distribusi Tanaman pada Dataset')
plt.xlabel('Tanaman')
plt.ylabel('Jumlah')
plt.show()

"""Dapat dilihat pada distribusi tersebut bahwa Setiap tanaman memiliki jumlah yang sama rata, yaitu sekitar 100 data per kelas. Hal ini menandakan bahwa dataset seimbang (balanced), sehingga model tidak akan bias terhadap kelas tertentu saat dilatih, yang merupakan kondisi ideal untuk klasifikasi.

**Korelasi antar fitur**
"""

plt.figure(figsize=(10, 8))

# Pilih hanya kolom numerik untuk korelasi
numerical_features = df.select_dtypes(include=[np.number])

sns.heatmap(numerical_features.corr(), annot=True, cmap='YlGnBu')
plt.title("Korelasi Antar Fitur Numerik")
plt.show()

"""Heatmap pada gambar menunjukkan **korelasi antar fitur numerik** dalam dataset. Terlihat bahwa fitur **P (fosfor)** dan **K (kalium)** memiliki korelasi cukup tinggi (0.74), artinya keduanya cenderung meningkat atau menurun bersama. Sementara fitur lain seperti suhu, kelembaban, pH, dan curah hujan memiliki korelasi rendah satu sama lain, menunjukkan bahwa sebagian besar fitur bersifat **independen**. Hal ini baik untuk model karena mengurangi risiko multikolinearitas dan memberikan informasi yang lebih beragam.

#Preprocessing Data

**Encoding Label**

Encoding label dilakukan supaya data kategori diubah jadi angka agar model machine learning bisa memprosesnya.
"""

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Inisialisasi label encoder
le = LabelEncoder()

# Encode kolom label
df['label_encoded'] = le.fit_transform(df['label'])

# Fitur dan target
X = df.drop(columns=['label', 'label_encoded'])
y = df['label_encoded']

# Informasi tipe data
df.info()

"""pada output di atas dapat dilihat bahwa Dataframe ini berisi 2200 baris dengan 9 kolom, termasuk data numerik seperti `N`, `P`, `K`, `temperature`, dan data kategorikal pada kolom `label`. Kolom `label` sudah diubah menjadi angka pada kolom `label_encoded` melalui encoding. Semua data lengkap tanpa nilai kosong.

**Split data**

Data di-split supaya model dilatih pada data train dan diuji pada data test untuk mengukur performa model secara objektif.
"""

# Split data: 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Ukuran data train: {X_train.shape}")
print(f"Ukuran data test: {X_test.shape}")

"""Output menunjukkan data train berisi 1760 baris dan data test 440 baris, dengan 7 fitur di masing-masing, sesuai proporsi split 80:20.

#Modelling dan Evaluasi

Pada tahap modelling dan evaluasi ini menggunakan tiga algoritma untuk perbandingan performanya yaitu Random Forest, XGBoost, dan SVM.

**Random Forest**
"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

"""**Evaluasi Model Random Forest**"""

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Prediksi
y_pred_rf = rf.predict(X_test)

# Evaluasi teks
print("=== Random Forest ===")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_rf)

# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu", cbar=False,
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix - Random Forest", fontsize=16)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""Model Random Forest berhasil mencapai akurasi sangat tinggi sebesar 99,55% pada data uji. Dari classification report terlihat bahwa hampir semua kelas memiliki precision, recall, dan f1-score mendekati 1, menunjukkan performa model yang sangat baik dan konsisten dalam mengklasifikasikan setiap kelas dengan akurat. Hanya beberapa kelas kecil seperti kelas 2, 8, 11, dan 20 yang memiliki nilai recall atau precision sedikit di bawah 1, tapi tetap sangat baik. Secara keseluruhan, model ini sangat efektif dalam mengenali pola pada data dan menghasilkan prediksi yang akurat.

**XGBoost**
"""

!pip install xgboost --quiet

from xgboost import XGBClassifier

# Inisialisasi tanpa use_label_encoder
xgb = XGBClassifier(eval_metric='mlogloss', random_state=42)
xgb.fit(X_train, y_train)

"""**Evaluasi Model XCBoost**"""

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

y_pred_xgb = xgb.predict(X_test)

print("=== XGBoost Classifier ===")
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("Classification Report:\n", classification_report(y_test, y_pred_xgb))

cm_xgb = confusion_matrix(y_test, y_pred_xgb)

plt.figure(figsize=(12, 10))
sns.heatmap(cm_xgb, annot=True, fmt="d", cmap="PuBuGn", cbar=False,
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix - XGBoost", fontsize=16)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""Model XGBoost berhasil mencapai akurasi tinggi sebesar 99,32% pada data uji. Dari classification report terlihat bahwa sebagian besar kelas memiliki precision, recall, dan f1-score mendekati 1, menandakan performa model yang sangat baik dalam mengklasifikasikan setiap kelas dengan tepat. Beberapa kelas seperti kelas 8, 10, 13, 14, dan 20 menunjukkan nilai recall atau precision sedikit di bawah 1, namun tetap sangat baik dan tidak signifikan menurunkan kualitas prediksi. Secara keseluruhan, model XGBoost menunjukkan efektivitas tinggi dalam mengenali pola data dan memberikan prediksi yang akurat.

**SVM (Support Vector Machine)**
"""

from sklearn.svm import SVC

# Inisialisasi model
svm_model = SVC(random_state=42)

# Training
svm_model.fit(X_train, y_train)

"""**Evaluasi Model SVM**"""

# Prediksi dan evaluasi
y_pred_svm = svm_model.predict(X_test)

print("=== Support Vector Machine ===")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Classification Report:\n", classification_report(y_test, y_pred_svm, target_names=le.classes_))

# Visualisasi confusion matrix
cm = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix - SVM')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Model Support Vector Machine (SVM) mencapai akurasi sebesar 98,41% pada data uji, menunjukkan performa yang sangat baik. Dari classification report, mayoritas kelas memiliki precision, recall, dan f1-score yang mendekati 1, menandakan model mampu mengklasifikasikan sebagian besar kelas dengan tepat. Namun, beberapa kelas seperti jute dan rice memiliki recall yang lebih rendah (masing-masing 1.00 dan 0.75), yang berarti model kurang optimal dalam mendeteksi semua sampel kelas tersebut. Meskipun begitu, secara keseluruhan, model SVM tetap efektif dan menghasilkan prediksi yang akurat dengan sedikit penurunan performa pada beberapa kelas tertentu.

**Perbandingan ketiga algorima (Random forest, XGBoost dan SVM**
"""

import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Train model SVM
svm_model = SVC(random_state=42)
svm_model.fit(X_train, y_train)

# Hitung akurasi ketiga model
acc_rf = accuracy_score(y_test, rf.predict(X_test))
acc_xgb = accuracy_score(y_test, xgb.predict(X_test))
acc_svm = accuracy_score(y_test, svm_model.predict(X_test))

# Data untuk plot
models = ['Random Forest', 'XGBoost', 'SVM']
accuracies = [acc_rf, acc_xgb, acc_svm]

# Plot diagram batang
plt.figure(figsize=(8,5))
bars = plt.bar(models, accuracies, color=['skyblue', 'salmon', 'lightgreen'])
plt.ylim([0,1])
plt.ylabel('Accuracy')
plt.title('Perbandingan Akurasi Model')

# Tambahkan nilai akurasi di atas batang
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f"{yval:.4f}", ha='center', va='bottom')

plt.show()

"""1. Semua model memiliki performa sangat tinggi, dengan akurasi di atas 98%, menandakan bahwa dataset kemungkinan bersih, seimbang, dan mudah dipisahkan antar kelas.
2. Random Forest menghasilkan akurasi tertinggi (99.55%), sedikit lebih baik dari XGBoost dan SVM.
3. XGBoost sangat mendekati Random Forest, dengan selisih hanya 0.23%. Ini menunjukkan bahwa keduanya bekerja sangat baik untuk dataset ini.
4. SVM sedikit di bawah dua model lainnya, namun tetap dengan akurasi sangat baik.
"""